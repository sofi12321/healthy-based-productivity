{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# This file is used to train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-07-11T08:07:40.373122Z",
     "end_time": "2023-07-11T08:07:40.466561Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sc_model import SC_LSTM as Model"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Device init"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 11 08:08:58 2023       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 530.41.03              Driver Version: 530.41.03    CUDA Version: 12.1     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce GTX 1650 Ti      Off| 00000000:01:00.0  On |                  N/A |\r\n",
      "| N/A   45C    P8                7W /  N/A|    941MiB /  4096MiB |     28%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A       572      G   /usr/lib/Xorg                               403MiB |\r\n",
      "|    0   N/A  N/A       636      G   /usr/bin/kwalletd5                            1MiB |\r\n",
      "|    0   N/A  N/A       725      G   /usr/bin/ksmserver                            1MiB |\r\n",
      "|    0   N/A  N/A       727      G   /usr/bin/kded5                                1MiB |\r\n",
      "|    0   N/A  N/A       730      G   /usr/bin/kwin_x11                           138MiB |\r\n",
      "|    0   N/A  N/A       799      G   ...b/polkit-kde-authentication-agent-1       15MiB |\r\n",
      "|    0   N/A  N/A       801      G   /usr/lib/xdg-desktop-portal-kde               1MiB |\r\n",
      "|    0   N/A  N/A       955      G   /usr/lib/kdeconnectd                          1MiB |\r\n",
      "|    0   N/A  N/A       958      G   /usr/bin/latte-dock                          20MiB |\r\n",
      "|    0   N/A  N/A       966      G   /usr/bin/kaccess                              1MiB |\r\n",
      "|    0   N/A  N/A       974      G   /usr/bin/kalendarac                           1MiB |\r\n",
      "|    0   N/A  N/A       979      G   /usr/bin/kmix                                 1MiB |\r\n",
      "|    0   N/A  N/A       988      G   /usr/lib/DiscoverNotifier                     1MiB |\r\n",
      "|    0   N/A  N/A      1182      G   /usr/bin/ktorrent                             1MiB |\r\n",
      "|    0   N/A  N/A      1209      G   /usr/bin/yakuake                             15MiB |\r\n",
      "|    0   N/A  N/A      2023      G   ...bin/plasma-browser-integration-host        1MiB |\r\n",
      "|    0   N/A  N/A     52012      G   /usr/bin/krunner                             36MiB |\r\n",
      "|    0   N/A  N/A     74929      G   /usr/bin/telegram-desktop                    32MiB |\r\n",
      "|    0   N/A  N/A    145609      G   /usr/bin/plasmashell                         89MiB |\r\n",
      "|    0   N/A  N/A    157456      G   ...35454217,2260994688081749193,131072      133MiB |\r\n",
      "|    0   N/A  N/A    225781      G   /usr/bin/konsole                              1MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "NVIDIA GeForce GTX 1650 Ti\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if device.type == 'cuda':\n",
    "    !nvidia-smi\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print(\"No GPU :(\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-11T08:07:40.386321Z",
     "end_time": "2023-07-11T08:07:40.642235Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-11T08:07:40.586844Z",
     "end_time": "2023-07-11T08:07:40.642901Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "       Label Number  Duration  Importance Start Time        Date\n0                 3        90           2      08:45  11/07/2023\n1                 3       160           3      13:00  11/07/2023\n2                 1        20           3      17:05  11/07/2023\n3                 2        40           1      18:40  11/07/2023\n4                 0        15           0      21:45  11/07/2023\n...             ...       ...         ...        ...         ...\n66691             1        35           1      13:15  25/11/2050\n66692             0         5           0      15:25  25/11/2050\n66693             1        95           1      17:45  25/11/2050\n66694             0        10           0      20:15  25/11/2050\n66695             2        60           1      21:15  25/11/2050\n\n[66696 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Label Number</th>\n      <th>Duration</th>\n      <th>Importance</th>\n      <th>Start Time</th>\n      <th>Date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>90</td>\n      <td>2</td>\n      <td>08:45</td>\n      <td>11/07/2023</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>160</td>\n      <td>3</td>\n      <td>13:00</td>\n      <td>11/07/2023</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>20</td>\n      <td>3</td>\n      <td>17:05</td>\n      <td>11/07/2023</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>40</td>\n      <td>1</td>\n      <td>18:40</td>\n      <td>11/07/2023</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>15</td>\n      <td>0</td>\n      <td>21:45</td>\n      <td>11/07/2023</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>66691</th>\n      <td>1</td>\n      <td>35</td>\n      <td>1</td>\n      <td>13:15</td>\n      <td>25/11/2050</td>\n    </tr>\n    <tr>\n      <th>66692</th>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>15:25</td>\n      <td>25/11/2050</td>\n    </tr>\n    <tr>\n      <th>66693</th>\n      <td>1</td>\n      <td>95</td>\n      <td>1</td>\n      <td>17:45</td>\n      <td>25/11/2050</td>\n    </tr>\n    <tr>\n      <th>66694</th>\n      <td>0</td>\n      <td>10</td>\n      <td>0</td>\n      <td>20:15</td>\n      <td>25/11/2050</td>\n    </tr>\n    <tr>\n      <th>66695</th>\n      <td>2</td>\n      <td>60</td>\n      <td>1</td>\n      <td>21:15</td>\n      <td>25/11/2050</td>\n    </tr>\n  </tbody>\n</table>\n<p>66696 rows Ã— 5 columns</p>\n</div>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Data.PreprocessorOfGeneratedData import Preprocessor\n",
    "\n",
    "preproc = Preprocessor()\n",
    "\n",
    "data = pd.read_csv('../Data/schedule_gen.csv')\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-11T08:08:59.377944Z",
     "end_time": "2023-07-11T08:08:59.378384Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_data, type_vector, output_data = preproc.preprocess('../Data/schedule_gen.csv')\n",
    "# input_data = np.array(input_data, dtype=np.float64)\n",
    "# pd.DataFrame(input_data)\n",
    "input_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-11T08:07:40.668280Z",
     "end_time": "2023-07-11T08:08:44.773161Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make the data positive\n",
    "output_data = np.abs(np.array(output_data, dtype=np.float64))\n",
    "pd.DataFrame(output_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-11T08:08:44.769310Z",
     "end_time": "2023-07-11T08:08:44.773497Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ScheduleDataset(Dataset):\n",
    "    def __init__(self, input_data, type_vector, output_vector, task_types='all', transform=None):\n",
    "        if task_types == 'all':\n",
    "            self.input_data = input_data\n",
    "            self.type_vector = type_vector\n",
    "            self.output_vector = output_vector\n",
    "        elif task_types == 'resched':\n",
    "            self.input_data = []\n",
    "            self.type_vector = []\n",
    "            self.output_vector = []\n",
    "            for i in range(len(input_data)):\n",
    "                if type_vector[i] == \"resched\":\n",
    "                    self.input_data.append(input_data[i])\n",
    "                    self.type_vector.append(type_vector[i])\n",
    "                    self.output_vector.append(output_vector[i])\n",
    "        elif task_types == 'non-resched':\n",
    "            self.input_data = []\n",
    "            self.type_vector = []\n",
    "            self.output_vector = []\n",
    "            for i in range(len(input_data)):\n",
    "                if type_vector[i] == \"non-resched\":\n",
    "                    self.input_data.append(input_data[i])\n",
    "                    self.type_vector.append(type_vector[i])\n",
    "                    self.output_vector.append(output_vector[i])\n",
    "        else:\n",
    "            raise ValueError(\"task_types must be 'all', 'resched', or 'non-resched'\")\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_data[idx], self.type_vector[idx], self.output_vector[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-11T08:08:44.769424Z",
     "end_time": "2023-07-11T08:08:44.773594Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "resched_dataset = ScheduleDataset(input_data, type_vector, output_data, task_types='resched')\n",
    "non_resched_dataset = ScheduleDataset(input_data, type_vector, output_data, task_types='non-resched')\n",
    "all_dataset = ScheduleDataset(input_data, type_vector, output_data, task_types='all')\n",
    "\n",
    "print(f\"Resched dataset size: {len(resched_dataset)}\\n\"\n",
    "      f\"Non-resched dataset size: {len(non_resched_dataset)}\\n\"\n",
    "      f\"All dataset size: {len(all_dataset)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-11T07:21:29.045699Z",
     "end_time": "2023-07-11T07:21:29.132473Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create dataloaders"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "# resched_dataset_size = len(resched_dataset)\n",
    "# train_size = int(resched_dataset_size * 0.8)\n",
    "# test_size = resched_dataset_size - train_size\n",
    "#\n",
    "# train_resched_dataset, test_resched_dataset = torch.utils.data.random_split(resched_dataset, [train_size, test_size])\n",
    "\n",
    "train_resched_dataloader = DataLoader(resched_dataset, batch_size=batch_size)\n",
    "# valid_resched_dataloader = DataLoader2(resched_dataset, batch_size=batch_size)\n",
    "\n",
    "train_non_resched_dataloader = DataLoader(non_resched_dataset, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-11T07:21:29.128308Z",
     "end_time": "2023-07-11T07:21:29.132651Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create free time slots generator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Data.GeneratorOfAvailableTimeslots import GeneratorOfAvailableTimeslots\n",
    "\n",
    "time_slots_gen = GeneratorOfAvailableTimeslots(5)\n",
    "time_slots = time_slots_gen.generate_available_timeslots()\n",
    "\n",
    "time_slots      # TODO: why all the intervals are closed?\n",
    "single_interval = time_slots[0]\n",
    "single_interval\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-11T07:21:29.128375Z",
     "end_time": "2023-07-11T07:21:29.169905Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Init the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# check if the dataloader works and get the input and output sizes\n",
    "in_features = None\n",
    "out_features = None\n",
    "for i, (features, a, ans) in enumerate(train_resched_dataloader):\n",
    "    in_features = features.shape[1]             # 13\n",
    "    out_features = ans.shape[1]                 # 3\n",
    "    break\n",
    "\n",
    "n_layers = 1\n",
    "hidden_size = 124\n",
    "hidden_injector = 64\n",
    "\n",
    "# Create the model\n",
    "SC_LSTM = Model(in_features, n_layers, hidden_size, out_features, batch_size, hidden_injector=hidden_injector).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-11T07:21:29.169287Z",
     "end_time": "2023-07-11T07:21:29.171275Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Configure hyper-parameters\n",
    "epochs = 7\n",
    "learning_rate = 0.001\n",
    "loss_func = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(SC_LSTM.parameters(), lr=learning_rate)\n",
    "\n",
    "history = []\n",
    "loss_accomulator = []\n",
    "mean_loss = None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-11T07:21:29.172954Z",
     "end_time": "2023-07-11T07:21:29.213335Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Firstly train the LSTM using only reschedulable tasks\n",
    "SC_LSTM.train_model(mode='lstm')\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    SC_LSTM.reset_states()\n",
    "    for i, (X, task_type, Y) in enumerate(tqdm(train_resched_dataloader, desc=f\"Epoch: {epoch + 1}, Mean Loss: {mean_loss}\", leave=False, colour='green')):\n",
    "\n",
    "        # Convert X and Y to the correct type\n",
    "        X = torch.Tensor(X).type(torch.float32).to(device)\n",
    "        Y = torch.Tensor(Y).type(torch.float32).to(device)\n",
    "\n",
    "        # Make prediction\n",
    "        Y_pred = SC_LSTM.forward(X, task_type=task_type, free_time_slots=single_interval, save_states=True)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_func(Y_pred.view(-1, ), Y.view(-1, ))\n",
    "\n",
    "        # print(f\"Predicted: {Y_pred[0]}\\n Real: {Y[0]}\\n\")\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Append loss to list\n",
    "        loss_accomulator.append(loss.item())\n",
    "\n",
    "    mean_loss = np.mean(loss_accomulator)\n",
    "    history.append(mean_loss)\n",
    "    loss_accomulator = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-11T07:21:29.213210Z",
     "end_time": "2023-07-11T07:31:56.661707Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot the loss history\n",
    "plt.plot(history)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss history\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-11T07:31:56.679147Z",
     "end_time": "2023-07-11T07:31:56.865651Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Configure hyper-parameters\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "loss_func = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(SC_LSTM.parameters(), lr=learning_rate)\n",
    "\n",
    "history = []\n",
    "loss_accomulator = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-11T07:31:56.848210Z",
     "end_time": "2023-07-11T07:31:56.865808Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Now train the injector using non-reschedulable tasks\n",
    "SC_LSTM.train_model(mode='injector')\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    SC_LSTM.reset_states()\n",
    "\n",
    "    for i, (X, task_type, Y) in enumerate(tqdm(train_non_resched_dataloader, desc=f\"Epoch: {epoch + 1}, Mean Loss: {mean_loss}\", leave=False, colour='green')):\n",
    "\n",
    "        # Convert X and Y to the correct type\n",
    "        X = torch.Tensor(X).type(torch.float32).to(device)\n",
    "        Y = torch.Tensor(Y).type(torch.float32).to(device)\n",
    "\n",
    "        # Make prediction\n",
    "        Y_pred = SC_LSTM.forward(X, task_type=task_type, free_time_slots=single_interval, save_states=True)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_func(Y_pred.view(-1, ), Y.view(-1, ))\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Append loss to list\n",
    "        loss_accomulator.append(loss.item())\n",
    "\n",
    "    mean_loss = np.mean(loss_accomulator)\n",
    "    history.append(mean_loss)\n",
    "    loss_accomulator = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-11T07:31:56.848244Z",
     "end_time": "2023-07-11T07:33:53.711897Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the loss history\n",
    "plt.plot(history)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss history\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-11T07:33:53.700150Z",
     "end_time": "2023-07-11T07:33:53.876754Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(SC_LSTM.state_dict(), \"sc_lstm_weights.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-11T07:33:53.823250Z",
     "end_time": "2023-07-11T07:33:53.876926Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
